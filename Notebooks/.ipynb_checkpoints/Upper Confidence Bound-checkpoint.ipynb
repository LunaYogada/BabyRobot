{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the power socket setup, base classes and helpers\n",
    "# (see PowerSocketSystem.py)\n",
    "from PowerSocketSystem import *"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Upper Confidence Bound (UCB) Algorithm\n",
    "\n",
    "As we've seen, Epsilon-Greedy has linear regret. It continues to explore the set of all actions, long after it has gained sufficient knowledge to know which of these actions are bad actions to take.\n",
    "\n",
    "A better approach, in terms of maximising the total reward, would be to restrict the sampling over time, to the actions showing the best performance. This is the exact approach taken by the Upper Confidence Bound (UCB) strategy.\n",
    "\n",
    "Rather than performing exploration by simply selecting an arbitrary action, chosen with a probability that remains constant, the UCB algorithm changes its exploration-exploitation balance as it gathers more knowledge of the environment. It moves from being primarily focused on exploration, when actions that have been tried the least are preferred, to instead concentrate on exploitation, selecting the action with the highest estimated reward.\n",
    "\n",
    "With UCB, 'Aₜ', the action chosen at time step 't', is given by:\n",
    "\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "where;\n",
    "Qₜ(a) is the estimated value of action 'a' at time step 't'.\n",
    "Nₜ(a) is the number of times that action 'a' has been selected, prior to time 't'.\n",
    "'c' is a constant, whose role will be described shortly.\n",
    "\n",
    "\n",
    "\n",
    "The formula for UCB can be thought of as being formed from 2 distinct parts:\n",
    "\n",
    "* Qₜ(a) represents the exploitation part of the equation. UCB is based on the principle of \"optimism in the fact of uncertainty\", which basically means, if you don't know which action is best then choose the one that currently looks to be the best. Taking this half of the equation by itself will do exactly that: the action that currently has the highest estimated reward will be the chosen action.\n",
    "\n",
    "\n",
    "* The second half of the equation adds exploration, with the degree of exploration being controlled by the hyper-parameter 'c'. Effectively this half of the equation provides a measure of the uncertainty for the action's reward estimate.\n",
    "If an action hasn't been tried very often, or not at all, then Nₜ(a) will be small. Consequently the uncertainty term will be large, making this action more likely to be selected. Every time an action is taken we become more confident about its estimate. In this case Nₜ(a) increments, and so the uncertainty term decreases, making it less likely that this action will be selected as a result of exploration (although it may still be selected as the action with the highest value, due to the exploitation term).\n",
    "When an action is not being selected, the uncertainty term will grow slowly, due to the log function in the numerator. Whereas, every time that the action is selected, the uncertainty will shrink rapidly due to the increase in Nₜ(a) being linear. So the exploration term will be larger for actions that have been selected infrequently, due to the uncertainty in the estimates of their rewards.\n",
    "As time progresses the exploration term gradually decreases (since as 'n' goes to infinity log n/n goes to zero), until eventually actions are selected based only on the exploitation term.\n",
    "\n",
    "The relative contributions of each of the exploration and exploitation terms can be seen in the graph below. Here, to simplify the comparison, we've taken only the first 2 sockets from our standard set. These 2 sockets have mean reward values of 6 and 4 seconds of charge respectively and it can be seen as time progresses that the estimate of the reward (the Q value, shown by the shaded bars) converges on this value for each socket.\n",
    "\n",
    "But the UCB formula also contains the uncertainty term, represented by the solid part of the bar for each socket, and the socket that gets selected is the one with the maximum value of Q plus this uncertainty term. So, on the graph, at each time step, the socket that will be selected is the one with tallest bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCBSocket( PowerSocket ):\n",
    "\n",
    "    def __init__( self, q, **kwargs ):    \n",
    "        \"\"\" initialize the UCB socket \"\"\"                  \n",
    "        \n",
    "        # store the confidence level controlling exploration\n",
    "        self.confidence_level = kwargs.pop('confidence_level', 2.0)       \n",
    "                \n",
    "        # pass the true reward value to the base PowerSocket   \n",
    "        super().__init__(q)           \n",
    "        \n",
    "    def uncertainty(self, t): \n",
    "        \"\"\" calculate the uncertainty in the estimate of this socket's mean \"\"\"\n",
    "        if self.n == 0: return float('inf')                         \n",
    "        return self.confidence_level * (np.sqrt(np.log(t) / self.n))         \n",
    "        \n",
    "    def sample(self,t):\n",
    "        \"\"\" the UCB reward is the estimate of the mean reward plus its uncertainty \"\"\"\n",
    "        return self.Q + self.uncertainty(t) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCBSocketTester( SocketTester ):\n",
    "\n",
    "    def __init__(self, socket_order=socket_order, confidence_level=2.0 ):                  \n",
    "        \"\"\" initialize the socket tester \"\"\"                  \n",
    "        super().__init__(socket = UCBSocket, \n",
    "                         socket_order = socket_order, \n",
    "                         confidence_level = confidence_level, \n",
    "                         number_of_stats = 3) # a UCB socket tester records 3 bits of information over a run\n",
    "        \n",
    "    def get_socket_stats( self, t ):\n",
    "        \"\"\" record the current values of each socket \"\"\"\n",
    "        socket_stats = [[socket.Q,socket.n,socket.uncertainty(t+1)] for socket in self.sockets]\n",
    "        return socket_stats   \n",
    "\n",
    "    def select_socket( self, t ):\n",
    "        \"\"\" choose the socket with the current highest UCB reward \"\"\"\n",
    "        socket_index = random_argmax([socket.sample(t+1) for socket in self.sockets])     \n",
    "        return socket_index        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 114.77150488946722)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do a single run with only 2 sockets to examine how the exploration and exploitation terms of the UCB equation vary\n",
    "number_of_sockets = 2\n",
    "number_of_steps = 20\n",
    "\n",
    "# set the random seed to produce a recreatable graph\n",
    "random.seed(0) \n",
    "np.random.seed(0)\n",
    "\n",
    "tester = UCBSocketTester( socket_order[:number_of_sockets], confidence_level = 3.0 )\n",
    "tester.run( number_of_steps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the parameters to graph from the socket stats\n",
    "estimates = tester.socket_stats[:,:,0]\n",
    "trials = tester.socket_stats[:,:,1]\n",
    "uncertainty = tester.socket_stats[:,:,2]\n",
    "\n",
    "# the label locations\n",
    "# - start the examination after all sockets have been tried once\n",
    "x = np.arange(len(estimates[:,0]))[2:]  \n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "rects1 = [ plt.bar(x, uncertainty[2:,0]+estimates[2:,0], align='edge', width= -width, label='Socket 1 - Uncertainty'),\n",
    "           plt.bar(x, estimates[2:,0], align='edge', width= -width, label='Socket 1 - Q', hatch='//')]\n",
    "\n",
    "rects2 = [ plt.bar(x, uncertainty[2:,1]+estimates[2:,1], align='edge',width= width, label='Socket 2 - Uncertainty'),\n",
    "           plt.bar(x, estimates[2:,1], align='edge',width= width, label='Socket 2 - Q', hatch='//')]\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('UCB Value')\n",
    "ax.set_xlabel('Time Steps')\n",
    "ax.set_title('UCB Exploration-Exploitation', fontsize=24, fontweight='bold')\n",
    "ax.legend(fontsize=24)\n",
    "ax.set_xticks(x)\n",
    "\n",
    "\n",
    "def autolabel(rects,index,trials):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its number of trials\"\"\"\n",
    "\n",
    "    for i,rect in enumerate(rects[0]):\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:.0f}'.format(trials[i+2,index]),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    size=16,\n",
    "                    ha='center', va='bottom')  \n",
    "\n",
    "\n",
    "autolabel(rects1,0,trials)\n",
    "autolabel(rects2,1,trials)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('ucb_exploration_exploitation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the points to note from the graph are as follows:\n",
    "\n",
    "* The socket uncertainty value is set to infinity if a socket has not yet been tried, causing an initial priming round to be performed, in which each action is tried once to get its initial value. This then avoids divide-by-zero errors in the exploration term when actions have not yet been tried and Nₜ(a) is equal to zero. Obviously this is only applicable when there are fewer possible actions 'k' than there are time steps 't', otherwise there wouldn't be enough time to try every action.\n",
    "\n",
    "\n",
    "* Due to the priming round the graph begins at time step 2. The number of times that each socket has been selected is shown by the number at the top of each bar. So, at time step 2, it can be seen that each socket has been selected once. Since each socket has been tried the same number of times the contribution of the uncertainty term is the same for each socket. However, due to its larger reward estimate 'Q', socket 1 has the largest total UCB value and is therefore selected by the argmax function.\n",
    "\n",
    "\n",
    "* At time step 3, socket 1 was the selected socket at the previous time step, so the count of the number of times it has been tried increases to 2. As a result the uncertainty term for this socket shrinks, so the solid blue bar can be seen to decrease in size. The hatched yellow bar also decreases due to this socket having been sampled and forming a better estimate for the true socket reward.\n",
    "On the other hand, socket 2 wasn't selected, so its reward estimate stays the same. The number of times it has been selected also stays the same, while the number of time steps increases, consequently the size of its uncertainty term increases, so the solid green bar can be seen to get bigger.\n",
    "However, the overall size of the UCB term for socket 1 is still greater than that of socket 2, so once again it is the socket that gets selected.\n",
    "\n",
    "\n",
    "* Eventually, at time step 5, socket 2's uncertainty term has increased sufficiently to make its total UCB value greater than that of socket 1 and so it is the socket that gets chosen. Once this happens its estimated reward value moves closer to the true mean reward, its uncertainty term shrinks and the whole process begins again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ucb_socket_percentages( confidence_values, socket_percentages, number_of_steps ):\n",
    "\n",
    "    df = pd.DataFrame(socket_percentages)\n",
    "    for socket in range(df.shape[1]):\n",
    "        plt.plot(confidence_values, df[socket]*100, label = f'{socket+1}', marker='o', linestyle='--')           \n",
    "\n",
    "    plt.plot(confidence_values, np.ones(df.shape[0])*20,'k')\n",
    "\n",
    "    plt.legend(title = 'Sockets')\n",
    "    plt.title('Socket Selection Percentage vs Confidence Level', fontsize=15)\n",
    "    plt.xlabel('Confidence Level')\n",
    "    plt.ylabel('Socket Selection (%)')\n",
    "     \n",
    "def plot_ucb_final_socket_estimates( confidence_values, final_socket_estimates, number_of_steps ):    \n",
    "    df = pd.DataFrame(final_socket_estimates)\n",
    "    for socket in range(df.shape[1]):\n",
    "        plt.plot(confidence_values, df[socket], label = f'{socket+1}', marker='o', linestyle='--')           \n",
    "\n",
    "    plt.legend(title = 'Sockets')\n",
    "    plt.title('Final Socket Estimate vs Confidence Level', fontsize=15)\n",
    "    plt.xlabel('Confidence Level')\n",
    "    plt.ylabel('Final Socket Estimate')    \n",
    "    \n",
    "def plot_ucb_reward_per_timestep( confidence_values, reward_per_timestep, number_of_steps, figsize=(10,8) ):\n",
    "    \n",
    "    plt.plot( confidence_values, reward_per_timestep, marker='o', linestyle='--', color='r') \n",
    "    plt.title('Mean Total Reward per Time Step vs Confidence Level', fontsize=15)\n",
    "    plt.xlabel('Confidence Level')\n",
    "    plt.ylabel('Mean Total Reward per Time Step')  \n",
    "    \n",
    "    \n",
    "def plot_ucb(confidence_values, reward_per_timestep, optimal_selected, socket_percentages, final_socket_estimates, number_of_steps ):\n",
    "    fig = plt.figure(figsize=(26,5))\n",
    "\n",
    "    plt.suptitle(f'Upper Confidence Bound: {number_of_steps} time-steps per run', fontsize=20, fontweight='bold')\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plot_ucb_socket_percentages( confidence_values, socket_percentages, number_of_steps )\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plot_ucb_reward_per_timestep( confidence_values, reward_per_timestep, number_of_steps )\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plot_ucb_final_socket_estimates( confidence_values, final_socket_estimates, number_of_steps )\n",
    "\n",
    "    plt.savefig(f\"ucb_{number_of_steps}.png\")\n",
    "\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ucb_experiment( number_of_tests, number_of_steps, confidence_level = 3.0):    \n",
    "    \n",
    "    experiment = SocketExperiment(socket_tester   = UCBSocketTester( confidence_level = confidence_level ),\n",
    "                                  number_of_tests = number_of_tests,\n",
    "                                  number_of_steps = number_of_steps)\n",
    "    experiment.run()\n",
    "    \n",
    "    return experiment.get_estimates(),\\\n",
    "           experiment.get_mean_total_reward(),\\\n",
    "           experiment.get_optimal_selected(),\\\n",
    "           experiment.get_socket_percentages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ucb_experiment( start, end, step = 0.01, number_of_tests = 100, number_of_steps = 300 ):     \n",
    "\n",
    "    test_values = []\n",
    "    reward_per_timestep = []\n",
    "    optimal_selected = []\n",
    "    socket_percentages = []\n",
    "    final_socket_estimates = []\n",
    "        \n",
    "    # iterate over the confidence level values\n",
    "    for confidence_level in tqdm( np.arange( start, (end+step), step ) ):\n",
    "        \n",
    "        # save the test value used to run this test\n",
    "        test_values.append( confidence_level )               \n",
    "        \n",
    "        mean_estimates, mean_reward_per_timestep, mean_optimal_selected, mean_socket_percentage = ucb_experiment( number_of_tests, number_of_steps, confidence_level )                           \n",
    "                \n",
    "        reward_per_timestep.append( mean_reward_per_timestep )\n",
    "        optimal_selected.append( mean_optimal_selected )\n",
    "        socket_percentages.append( mean_socket_percentage ) \n",
    "        final_socket_estimates.append( mean_estimates[-1] )\n",
    "     \n",
    "    return test_values, reward_per_timestep, optimal_selected, socket_percentages, final_socket_estimates          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many times each test should be run\n",
    "number_of_tests = 500\n",
    "\n",
    "# the confidence level test range\n",
    "start = 0\n",
    "stop = 100.0\n",
    "step = 5\n",
    "\n",
    "number_of_steps = 100\n",
    "confidence_values, reward_per_timestep, optimal_selected, socket_percentages, final_socket_estimates = \\\n",
    "    run_ucb_experiment( start, stop, step, number_of_tests, number_of_steps )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ucb(confidence_values, \n",
    "         reward_per_timestep, \n",
    "         optimal_selected, \n",
    "         socket_percentages, \n",
    "         final_socket_estimates, \n",
    "         number_of_steps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many times each test should be run\n",
    "number_of_tests = 1000\n",
    "\n",
    "# the confidence level test range\n",
    "start = 0.\n",
    "stop = 2.0\n",
    "step = 0.1\n",
    "\n",
    "number_of_steps = 50\n",
    "confidence_values, reward_per_timestep, optimal_selected, socket_percentages, final_socket_estimates = \\\n",
    "    run_ucb_experiment( start, stop, step, number_of_tests, number_of_steps )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(np.arange(0., 2.2, 0.2))\n",
    "plt.plot( confidence_values, reward_per_timestep, marker='o', linestyle='--', color='r') \n",
    "plt.title('Mean Total Reward per Time Step vs Confidence Level', fontsize=15)\n",
    "plt.xlabel('Confidence Level')\n",
    "plt.ylabel('Mean Total Reward per Time Step') \n",
    "plt.savefig(f\"ucb_reward_per_timestep{number_of_steps}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and test UCB sockets\n",
    "tester = UCBSocketTester( confidence_level = 0.6)\n",
    "tester.run( number_of_steps = 1000 )\n",
    "\n",
    "print(f'Mean Reward per Time Step = {tester.get_mean_reward()}')\n",
    "print(f'Optimal Socket Selected = {tester.get_optimal_socket_percentage()}')\n",
    "print(f'Socket Percentages = {tester.get_socket_percentages()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test 100 times with each test running for 1000 timesteps\n",
    "number_of_tests = 1000\n",
    "number_of_steps = 1000    \n",
    "\n",
    "experiment = SocketExperiment(socket_tester   = UCBSocketTester( confidence_level = 0.6 ),\n",
    "                              number_of_tests = number_of_tests,\n",
    "                              number_of_steps = number_of_steps)\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_trials = experiment.get_number_of_trials()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for socket in range(number_of_trials.shape[1]):\n",
    "    plt.plot(number_of_trials[:30,socket], label = f'{socket+1}')  \n",
    "    \n",
    "plt.title('UCB Number of Trials vs Time', fontsize=20, fontweight='bold')\n",
    "plt.legend(title = 'Sockets')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Number of Trials')\n",
    "\n",
    "plt.savefig(\"UCB_number_of_trials.png\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best socket has a true mean reward of 12\n",
    "cummulative_optimal_reward = [r*12 for r in range(1,number_of_steps+1)]\n",
    "\n",
    "# regret is the difference between the optimal reward and the actual reward \n",
    "regret = cummulative_optimal_reward - experiment.get_cumulative_reward_per_timestep()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "plt.suptitle(f'Upper Confidence Bound (UCB) Regret', fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(experiment.get_cumulative_reward_per_timestep(),label = \"Actual\")\n",
    "plt.plot(cummulative_optimal_reward, label =\"Optimal\")\n",
    "plt.plot(regret, label =\"Regret\")\n",
    "plt.legend()\n",
    "plt.title('Cumulative Reward vs Time', fontsize=15)\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Total Reward')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Regret vs Time', fontsize=15)\n",
    "plt.plot(regret)\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Regret')\n",
    "\n",
    "plt.savefig(f\"ucb_regret.png\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
