{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the power socket setup, base classes and helpers\n",
    "# (see PowerSocketSystem.py)\n",
    "from PowerSocketSystem import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Comparison of Bandit Algorithms\n",
    "\n",
    "We've now taken a look at some of the main algorithms used to tackle the multi-armed Bandit problem, although we've only just scratched the surface in terms of looking at all available algorithms (take a look at the Bandit Book if you'd like to see a whole lot more). The one question left to be answered is, which one is the best? Or, in other words, which algorithm will let Baby Robot get fully charged in the shortest amount of time.\n",
    "Restricting our experiment slightly further, and specifying the condition that Baby Robot has a maximum charge capacity of 3600 seconds worth of charge, which algorithm can get him to this limit the quickest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness we once again show all of the different Power Sockets that we'll be testing..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Standard Power Socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerSocket:\n",
    "    \"\"\" the base power socket class \"\"\"\n",
    "    \n",
    "    def __init__(self, q):                \n",
    "        self.q = q        # the true reward value              \n",
    "        self.initialize() # reset the socket\n",
    "        \n",
    "    def initialize(self):\n",
    "        self.Q = 0   # the estimate of this socket's reward value                \n",
    "        self.n = 0   # the number of times this socket has been tried        \n",
    "    \n",
    "    def charge(self):\n",
    "        \"\"\" return a random amount of charge \"\"\"\n",
    "        \n",
    "        # the reward is a guassian distribution with unit variance around the true\n",
    "        # value 'q'\n",
    "        value = np.random.randn() + self.q        \n",
    "        \n",
    "        # never allow a charge less than 0 to be returned        \n",
    "        return 0 if value < 0 else value\n",
    "                    \n",
    "    def update(self,R):\n",
    "        \"\"\" update this socket after it has returned reward value 'R' \"\"\"     \n",
    "    \n",
    "        # increment the number of times this socket has been tried\n",
    "        self.n += 1\n",
    "\n",
    "        # the new estimate of the mean is calculated from the old estimate\n",
    "        self.Q = (1 - 1.0/self.n) * self.Q + (1.0/self.n) * R\n",
    "    \n",
    "    def sample(self,t):\n",
    "        \"\"\" return an estimate of the socket's reward value \"\"\"\n",
    "        return self.Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Optimistic Greedy Power Socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Optimistic Socket class by inheriting from the standard Power Socket\n",
    "class OptimisticSocket( PowerSocket ):\n",
    "    def __init__( self, q, **kwargs ):    \n",
    "                      \n",
    "        # get the initial reqrd estimate from the kwargs\n",
    "        self.initial_estimate = kwargs.pop('initial_estimate', 0.) \n",
    "        \n",
    "        # pass the true reward value to the base PowerSocket             \n",
    "        super().__init__(q)         \n",
    "                \n",
    "    def initialize(self):        \n",
    "        # estimate of this socket's reward value \n",
    "        # - set to supplied initial value\n",
    "        self.Q = self.initial_estimate    \n",
    "        self.n = 0    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Upper Confidence Bounds Socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCBSocket( PowerSocket ):\n",
    "\n",
    "    def __init__( self, q, **kwargs ):    \n",
    "        \"\"\" initialize the UCB socket \"\"\"                  \n",
    "        \n",
    "        # store the confidence level controlling exploration\n",
    "        self.confidence_level = kwargs.pop('confidence_level', 2.0)        \n",
    "                \n",
    "        # pass the true reward value to the base PowerSocket   \n",
    "        super().__init__(q)           \n",
    "        \n",
    "    def uncertainty(self, t): \n",
    "        \"\"\" calculate the uncertainty in the estimate of this socket's mean \"\"\"\n",
    "        if self.n == 0: return float('inf')                         \n",
    "        return self.confidence_level * (np.sqrt(np.log(t) / self.n))         \n",
    "        \n",
    "    def sample(self,t):\n",
    "        \"\"\" the UCB reward is the estimate of the mean reward plus its uncertainty \"\"\"\n",
    "        return self.Q + self.uncertainty(t) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Gaussian Thompson Sampling Socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianThompsonSocket( PowerSocket ):\n",
    "    def __init__(self, q):                \n",
    "                \n",
    "        self.τ_0 = 0.0001  # the posterior precision\n",
    "        self.μ_0 = 1       # the posterior mean\n",
    "        \n",
    "        # pass the true reward value to the base PowerSocket             \n",
    "        super().__init__(q)         \n",
    "        \n",
    "    def sample(self,t):\n",
    "        \"\"\" return a value from the the posterior normal distribution \"\"\"\n",
    "        return (np.random.randn() / np.sqrt(self.τ_0)) + self.μ_0    \n",
    "                    \n",
    "    def update(self,R):\n",
    "        \"\"\" update this socket after it has returned reward value 'R' \"\"\"   \n",
    "\n",
    "        # do a standard update of the estimated mean\n",
    "        super().update(R)    \n",
    "               \n",
    "        # update the mean and precision of the posterior\n",
    "        self.μ_0 = ((self.τ_0 * self.μ_0) + (self.n * self.Q))/(self.τ_0 + self.n)        \n",
    "        self.τ_0 += 1       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Epsilon Greedy Socket Tester\n",
    "\n",
    "Note that Epsilon Greedy just uses the standard power socket. Instead of cusomizing the power socket class it instead modifies the socket selection algorithm, to randomly select from the complete set of sockets when the probability value is less than the defined value of epsilon.\n",
    "\n",
    "All other algorithms just use the standard socket selection routine, which always chooses the socket that returns the highest reward on the current time-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedySocketTester( SocketTester ):\n",
    "\n",
    "    def __init__(self, epsilon = 0.2 ):  \n",
    "        \n",
    "        # create a standard socket tester\n",
    "        super().__init__() \n",
    "        \n",
    "        # save the probability of selecting the non-greedy action\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    \n",
    "    def select_socket( self, t ):\n",
    "        \"\"\" Epsilon-Greedy Socket Selection\"\"\"\n",
    "        \n",
    "        # probability of selecting a random socket\n",
    "        p = np.random.random()\n",
    "\n",
    "        # if the probability is less than epsilon then a random socket is chosen from the complete set\n",
    "        if p < self.epsilon:\n",
    "            socket_index = np.random.choice(self.number_of_sockets)\n",
    "        else:\n",
    "            # choose the socket with the current highest mean reward or arbitrary select a socket in the case of a tie            \n",
    "            socket_index = random_argmax([socket.sample() for socket in self.sockets])               \n",
    "        \n",
    "        return socket_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on the standard power socket problem\n",
    "\n",
    "Baby Robot has found himself in a charging room with 5 power sockets. Each of these has a unique mean power output with unit variance. By definition Baby Robot can take a maximum of 3600 seconds worth of charge. Let's find which algorithm can get him to this the quickest..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_test( tester ):\n",
    "    \"\"\" run one test using the supplied socket tester \"\"\"\n",
    "    \n",
    "    steps, total_reward = tester.run( number_of_steps = 500, maximum_total_reward = 3600 )\n",
    "\n",
    "    print(f'Mean Reward per Time Step = {tester.get_mean_reward()}')\n",
    "    print(f'Optimal Socket Selected = {tester.get_optimal_socket_percentage():0.3f}')\n",
    "    print(f'Socket Percentages = {tester.get_socket_percentages()}') \n",
    "\n",
    "    if total_reward < 3600:\n",
    "        print(f'Target total reward not achieved - reward = {total_reward}')\n",
    "    else:\n",
    "        print(f'Target total reward achieved in {steps} time-steps')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward per Time Step = 12.004568841547853\n",
      "Optimal Socket Selected = 1.000\n",
      "Socket Percentages = [0.000 0.000 0.000 1.000 0.000]\n",
      "Target total reward achieved in 300 time-steps\n"
     ]
    }
   ],
   "source": [
    "run_single_test( SocketTester( PowerSocket ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward per Time Step = 10.927301931585825\n",
      "Optimal Socket Selected = 0.791\n",
      "Socket Percentages = [0.076 0.036 0.048 0.791 0.048]\n",
      "Target total reward achieved in 330 time-steps\n"
     ]
    }
   ],
   "source": [
    "run_single_test( EpsilonGreedySocketTester( epsilon = 0.2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward per Time Step = 12.048423727882751\n",
      "Optimal Socket Selected = 0.987\n",
      "Socket Percentages = [0.003 0.003 0.003 0.987 0.003]\n",
      "Target total reward achieved in 299 time-steps\n"
     ]
    }
   ],
   "source": [
    "run_single_test( SocketTester( OptimisticSocket, initial_estimate = 20. ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward per Time Step = 11.982526380005707\n",
      "Optimal Socket Selected = 0.983\n",
      "Socket Percentages = [0.003 0.003 0.003 0.983 0.007]\n",
      "Target total reward achieved in 301 time-steps\n"
     ]
    }
   ],
   "source": [
    "run_single_test( SocketTester( UCBSocket, confidence_level = 0.6 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward per Time Step = 11.802571982618279\n",
      "Optimal Socket Selected = 0.987\n",
      "Socket Percentages = [0.003 0.003 0.003 0.987 0.003]\n",
      "Target total reward achieved in 306 time-steps\n"
     ]
    }
   ],
   "source": [
    "run_single_test( SocketTester( GaussianThompsonSocket ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
